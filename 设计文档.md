# Proposal: 一种基于冷热数据分离的GC策略

- Author(s):  [来逸瑞](https://github.com/wangshuil)，[朱猛猛](https://github.com/zhumeng98)
- Last updated:  2019.8.4

## 摘要

该提案的目的是减小TiKV的写放大。
为了达到这一目的，我们设计了一种基于冷热数据检测的GC方法，通过检测冷热数据来减少GC所需要写回的数据量，从而减小了写放大。
该提案会增加每次GC的时间，造成一定程度的空间放大，同时向LSM-tree中写回更多的数据。

## 背景

### LSM-tree
LSM-tree，即Log-Structured Merge-Tree，是一种数据结构，基于磁盘的顺序读写性能远优于随机读写这一事实来设计，通过多层次的SST组织，将所有访问转化为对磁盘的顺序读写从而提高KV数据库的性能。

### RocksDB
[RocksDB](https://github.com/facebook/rocksdb)是facebook实现的，基于LSM-tree结构的一款KV存储引擎。通过大量的工程优化达到了高于LevelDB的性能。

### 写放大
写放大，即Write Amplification，是由LSM-tree的结构引起的。在LSM-tree中插入一个KV对时，会先放入内存中，再经过LSM-tree的各个level向下compaction。每次compaction时，会读入Level i的1个SST和Level i+1的k个SST(k为放大因子)，再写回k个SST，因此造成了k倍 的放大。极端情况下，对k=10，5层结构的LSM-tree，写放大达到了1+1+10+10+10+10=42。写放大对LSM-tree的性能造成了极大的影响。

### KV分离和Titan
KV分离，提出自[Wisckey](https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf)。原理是通过把value单独存储在独立的vlog文件中，只向LSM-tree中插入key-index，减小了存储在LSM-tree中的内容，从而减小了写放大。Titan是由PingCAP实现的一个基于RocksDB的KV分离的KV存储引擎，把大于阈值的value分离出来，存储在blob file中。

### 垃圾回收GC
在KV分离的基础上，由于value写入了单独的log文件，当value需要修改时，原来的value便会无效化，因此需要回收对应的空间来减小磁盘空间占用。Titan的方法是，当发生compaction时，读取需要回收的blob file，删去无效的value，再写回磁盘。


## 提案

### 设计概念
冷数据和热数据的定义：冷数据是指长期未进行更新的KV键值对，而热数据即为经常进行更新的KV键值对。
考虑这样一种情况，一个KV存储中，有50%的数据经常发生变动，剩下的50%则不会改变。那么每次对该数据库做GC时，这些冷数据都会被重复的读取和写回。这种情况下，对这些冷数据的操作造成了大量的性能浪费。
因此，我们设计了一种基于冷热数据检测的GC。

### 运作方式
这个设计基于Titan。
我们需要修改存储在blob file中的KV对，增加一个cold_awareness域，记录该KV对经过了多少次GC仍未被更新。若一个KV对的cold_awareness值超过了阈值，则会被判定为冷数据。
对冷数据，我们采用不同的GC方法，把冷数据单独的存储到新的一组blob file中。这些冷数据组成的blob file，由于几乎不需要更新，很少会触发GC，从而减小了对这部分数据进行GC的开销。

### 可能的影响
Positive：
+ 由于避免了冷数据GC的开销，该设计将会减小Titan的写放大，并提高写性能。

Negative：
+ 判定冷数据的阈值需要仔细设计，否则会带来更多的GC，或者没有数据被判定为冷数据。
+ 在移动冷数据到新的blob file时，会向LSM-tree插入额外的key-index对。


## 替代方案

### Wisckey
Wisckey的GC是把整个vlog文件作为一个环，整体进行GC，带来了过大的GC开销。

### HashKV
[HashKV](https://www.usenix.org/conference/atc18/presentation/chan)的主要设计是，把key-value分离后，根据key的hash值插入对应的segment中。因此一次GC涉及到的数据量较小，减小了GC开销。同时HashKV还提供了冷热分离的解决方案，对冷数据按照类似Wisckey的vlog结构进行GC。
对比我们的设计和HashKV，HashKV的优劣有：
+ Positive：提供了更全面的storage management，性能更优。
+ Negative：难以基于Titan进行实现，需要大量的改动。

## 兼容性
#### 接口兼容性
该设计基于Titan，对任何的外部接口不做修改，原有业务可以直接接入我们的解决方案。

#### 存储兼容性
由于修改了blob file的结构，原有的以Titan引擎存储的KV数据库不能直接迁移到我们的解决方案上，需要对整个库进行读取-写入，迁移的开销较大。


## 实现

我们的解决方案分为以下几个部分：
+ 冷热数据感知
    + 增加cold_awareness域
    + 在每次GC时，对未更新的数据，增加cold_awareness值
    + 对cold_awareness超过阈值的数据标记为冷
+ 冷数据分离和存储
    + 对GC中新产生的冷数据，从原有的blob file中分离出来，写入新的文件
    + 对冷数据文件进行标记，并向LSM-tree中写回新的key-index对

第一步、修改blob文件的格式，增加记录数据重写次数的内容，并在GC时，并在垃圾回收（GC）时将重写的数据这个部分加一，同时要判断这个值的大小是否达到一个阈值，如果达到那么就会写入冷数据文件中。
第二步、修改垃圾回收的过程，在GC时同时创建两个blob文件，一个用来存储热数据，一个用来存储冷数据。并修改选择文件进行GC的策略，防止存放冷数据的blob文件由于文件大小过小而进行GC导致冷数据被重写。
第三步、对新修改的内容进行测试，通过不断的测试找到合适的冷热分离时的指标，以及GC时,选择文件小的blob文件进行GC的指标。并通过测试找到一些代码中的问题并解决这些问题。
第四步、尝试实现一个新的文件结构用来存储冷数据，解决由于一次GC产生的冷数据过少，而导致存放冷数据的blob文件大小过小，从而减少对这些冷数据文件的GC而产生的写放大。由于实现一个新的文件结构需要为这个文件结构提供很多供titan使用的接口，可能耗时会很长，导致来不及实现。

预计实现周期：1周

## 未来的优化方向

由于时间问题，我们初步决定直接使用Titan的blob file结构存储冷数据，这可能带来以下问题：
+ 新创建的blob file过小
+ 对冷数据创建的文件过多，增加了内存和磁盘占用

对此，我们可以实现新的可持久化结构，在收集到的冷数据达到阈值时再进行持久化，具体的实现方法略。
